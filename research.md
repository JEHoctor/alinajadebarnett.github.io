---
layout: page
title: Research
permalink: /research/
---

## Publications
1. Alina Jade Barnett, Fides Regina Schwartz, Chaofan Tao, Chaofan Chen, Yinhao Ren, Joseph Y. Lo, and Cynthia Rudin. “A Case-based Interpretable Deep Learning Model for Classification of Mass Lesions in Digital Mammography.” Nature Machine Intelligence. (2021). https://arxiv.org/abs/2103.12308
	- An interpretable neural network for analysing breast lesions that explains its image classifications while maintaining accuracy.
2. Jon Donnelly, Alina Jade Barnett, and Chaofan Chen. “Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. (2022). https://arxiv.org/abs/2111.15000
3. Alina Jade Barnett, Vaibhav Sharma, Neel Gajjar, Jerry Fang, Fides Regina Schwartz, Chaofan Chen, Joseph Y. Lo, and Cynthia Rudin. “Interpretable Deep Learning Models for Better Clinician-AI Com- munication in Clinical Mammography.” Medical Imaging 2022: Image Perception, Observer Performance, and Technology Assessment. SPIE. (2022).
4. Alina Jade Barnett, Fides Regina Schwartz, Chaofan Tao, Chaofan Chen, Yinhao Ren, Joseph Y. Lo, and Cynthia Rudin. “Interpretable Mammographic Image Classification using Cased-Based Reasoning and Deep Learning.” IJCAI-21 Workshop on Deep Learning, Case-Based Reasoning, and AutoML: Present and Future Synergies. (2021). https://arxiv.org/abs/2107.05605
5. Chaofan Chen, Oscar Li, Chaofan Tao, Alina Jade Barnett, Cynthia Rudin, and Jonathan K. Su. “This Looks Like That: Deep Learning for Interpretable Image Recognition.” Advances in Neural Information Processing Systems 32 (2019): 8930-8941. https://arxiv.org/abs/2103.12308
	- Spotlight (top 3%) paper at NeurIPS 2019
	- A neural network that explains its image classifications while maintaining accuracy.
	- 2018: Featured on “Data Science at Home” podcast (Episode 41)
	- 2018: Presented as a 3-minute thesis and poster at the French-American Doctoral Exchange, a program developed by the Office for Science and Technology of the Embassy of France.

## Papers Under Review
6. Yanchen Jessie Ou, Alina Jade Barnett, Anika Mitra, Fides Regina Schwartz, Chaofan Chen, Lars Grimm, Joseph Y. Lo, and Cynthia Rudin. “A User Interface to Communicate Interpretable AI Decisions to Radiologists.” (2022). [Co-first author]

## Grants
1. $19,831.00 PI for a Duke Incubation Fund Award from the Duke Innovation & Entrepreneurship Initiative. A multi-department interdisciplinary project for superior interpretability on neural networks that analyze mammograms. 2019–2021.



