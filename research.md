---
layout: page
title: Research
permalink: /research/
---

## Peer-Reviewed Publications
1. “A Case-based Interpretable Deep Learning Model for Classification of Mass Lesions in Digital Mammography.” Alina Jade Barnett, Fides Regina Schwartz, Chaofan Tao, Chaofan Chen, Yinhao Ren, Joseph Y. Lo, and Cynthia Rudin. Nature Machine Intelligence. (2021). https://rdcu.be/cDhJ7
	- An interpretable neural network for analysing breast lesions that explains its image classifications while maintaining accuracy.
2. “Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes.” Jon Donnelly, Alina Jade Barnett, and Chaofan Chen. CVPR: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. (2022). https://arxiv.org/abs/2111.15000
3. “Interpretable Deep Learning Models for Better Clinician-AI Communication in Clinical Mammography.” Alina Jade Barnett, Vaibhav Sharma, Neel Gajjar, Jerry Fang, Fides Regina Schwartz, Chaofan Chen, Joseph Y. Lo, and Cynthia Rudin. Medical Imaging 2022: Image Perception, Observer Performance, and Technology Assessment. SPIE. (2022).
4. “Interpretable Mammographic Image Classification using Cased-Based Reasoning and Deep Learning.” Alina Jade Barnett, Fides Regina Schwartz, Chaofan Tao, Chaofan Chen, Yinhao Ren, Joseph Y. Lo, and Cynthia Rudin. IJCAI-21 Workshop on Deep Learning, Case-Based Reasoning, and AutoML: Present and Future Synergies. (2021). https://arxiv.org/abs/2107.05605
5. “This Looks Like That: Deep Learning for Interpretable Image Recognition.” Chaofan Chen*, Oscar Li*, Chaofan Tao, Alina Jade Barnett, Cynthia Rudin, and Jonathan K. Su. NeurIPS: Advances in Neural Information Processing Systems 32 (2019): 8930-8941. https://arxiv.org/abs/2103.12308
	- Spotlight (top 3%) paper at NeurIPS 2019
	- A neural network that explains its image classifications while maintaining accuracy.
	- 2018: Featured on “Data Science at Home” podcast (Episode 41)
	- 2018: Presented as a 3-minute thesis and poster at the French-American Doctoral Exchange, a program developed by the Office for Science and Technology of the Embassy of France.

### Articles Under Review
6. “A User Interface to Communicate Interpretable AI Decisions to Radiologists.” Yanchen Jessie Ou*, Alina Jade Barnett*, Anika Mitra*, Fides Regina Schwartz, Chaofan Chen, Lars Grimm, Joseph Y. Lo, and Cynthia Rudin. (2022).

### Working Papers
7. "Mapping the Ictal-Interictal-Continuum Using Interpretable Machine Learning (ProtoPMed-EEG)." Alina Jade Barnett*, Zhicheng Guo*, Jin Jing*, Wendong Ge, M. Brandon Westover and Cynthia Rudin. (2022).
8. "Active Learning for Breast Mass Segmentation." Vaibhav Sharma*, Alina Jade Barnett*, Neal Hall, Avivah Wang, Fides Regina Schwartz, Chaofan Chen, Lars Grimm, Joseph Lo and Cynthia Rudin. (2022).
9. "High-Resolution ProtoPNet." Satvik Kishore, Alina Jade Barnett, Chaofan Chen, Fides Regina Schwartz, Joseph Lo and Cynthia Rudin. (2022).

## Recordings
1. "Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes." CVPR: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022. Slides and video capture by Alina Jade Barnett, narrated by Jon Donnelly, script jointly created by Jon and Alina. https://www.youtube.com/watch?v=2cgidJJtGU8
2. "Introduction and Code Demo for Industry Practitioners: Interpretable Image Classification with ProtoPNet and IAIA-BL." The Conference on Responsible Machine Learning 2021. https://www.youtube.com/watch?v=-IkQ5CbVTkE

## Grants
1. $19,831.00 PI for a Duke Incubation Fund Award from the Duke Innovation & Entrepreneurship Initiative. A multi-department interdisciplinary project for superior interpretability on neural networks that analyze mammograms. 2019–2021.



