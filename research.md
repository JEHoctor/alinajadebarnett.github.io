---
layout: page
title: Research
permalink: /research/
---

## Publications
1. “A Case-based Interpretable Deep Learning Model for Classification of Mass Lesions in Digital Mammography.” Alina Jade Barnett, Fides Regina Schwartz, Chaofan Tao, Chaofan Chen, Yinhao Ren, Joseph Y. Lo, and Cynthia Rudin. Nature Machine Intelligence. (2021). https://rdcu.be/cDhJ7
	- An interpretable neural network for analysing breast lesions that explains its image classifications while maintaining accuracy.
2. “Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes.” Jon Donnelly, Alina Jade Barnett, and Chaofan Chen. CVPR: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. (2022). https://arxiv.org/abs/2111.15000
3. “Interpretable Deep Learning Models for Better Clinician-AI Communication in Clinical Mammography.” Alina Jade Barnett, Vaibhav Sharma, Neel Gajjar, Jerry Fang, Fides Regina Schwartz, Chaofan Chen, Joseph Y. Lo, and Cynthia Rudin. Medical Imaging 2022: Image Perception, Observer Performance, and Technology Assessment. SPIE. (2022).
4. “Interpretable Mammographic Image Classification using Cased-Based Reasoning and Deep Learning.” Alina Jade Barnett, Fides Regina Schwartz, Chaofan Tao, Chaofan Chen, Yinhao Ren, Joseph Y. Lo, and Cynthia Rudin. IJCAI-21 Workshop on Deep Learning, Case-Based Reasoning, and AutoML: Present and Future Synergies. (2021). https://arxiv.org/abs/2107.05605
5. “This Looks Like That: Deep Learning for Interpretable Image Recognition.” Chaofan Chen, Oscar Li, Chaofan Tao, Alina Jade Barnett, Cynthia Rudin, and Jonathan K. Su. NeurIPS: Advances in Neural Information Processing Systems 32 (2019): 8930-8941. https://arxiv.org/abs/2103.12308
	- Spotlight (top 3%) paper at NeurIPS 2019
	- A neural network that explains its image classifications while maintaining accuracy.
	- 2018: Featured on “Data Science at Home” podcast (Episode 41)
	- 2018: Presented as a 3-minute thesis and poster at the French-American Doctoral Exchange, a program developed by the Office for Science and Technology of the Embassy of France.

## Articles Under Review
6. “A User Interface to Communicate Interpretable AI Decisions to Radiologists.” Yanchen Jessie Ou, Alina Jade Barnett, Anika Mitra, Fides Regina Schwartz, Chaofan Chen, Lars Grimm, Joseph Y. Lo, and Cynthia Rudin. (2022). [Co-first author]

## Working Papers
7. "Mapping the Ictal-Interictal-Continuum Using Interpretable Machine Learning (ProtoPMed-EEG)." Alina Jade Barnett, Zhicheng Guo, Wendong Ge, M. Brandon Westover, Jin Jing and Cynthia Rudin. (2022). [Co-first author]
8. "Active Learning for Breast Mass Segmentation." Vaibhav Sharma, Alina Jade Barnett, Neal Hall, Avivah Wang, Fides Regina Schwartz, Chaofan Chen, Lars Grimm, Joseph Lo and Cynthia Rudin. (2022). [Co-first author]
9. "High-Resolution ProtoPNet." Satvik Kishore, Alina Jade Barnett, Chaofan Chen, Fides Regina Schwartz, Joseph Lo and Cynthia Rudin. (2022). [Co-first author]

## Grants
1. $19,831.00 PI for a Duke Incubation Fund Award from the Duke Innovation & Entrepreneurship Initiative. A multi-department interdisciplinary project for superior interpretability on neural networks that analyze mammograms. 2019–2021.



